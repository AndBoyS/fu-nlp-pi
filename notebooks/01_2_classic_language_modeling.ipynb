{"cells":[{"cell_type":"markdown","id":"28bd3bfb","metadata":{"id":"28bd3bfb"},"source":["# Языковые модели на n-граммах\n","\n","__Автор задач: Блохин Н.В. (NVBlokhin@fa.ru)__\n","\n","Материалы:\n","* https://www.nltk.org/api/nltk.util.html\n","* https://web.stanford.edu/~jurafsky/slp3/3.pdf\n","* https://www.youtube.com/watch?v=QGT6XTeA3YQ"]},{"cell_type":"markdown","id":"0e0c795b","metadata":{"id":"0e0c795b"},"source":["## Задачи для совместного разбора"]},{"cell_type":"code","execution_count":1,"id":"6311d17d","metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["[nltk_data] Downloading package punkt to\n","[nltk_data]     C:\\Users\\anvbakhmatov\\AppData\\Roaming\\nltk_data...\n","[nltk_data]   Unzipping tokenizers\\punkt.zip.\n"]},{"data":{"text/plain":["True"]},"execution_count":1,"metadata":{},"output_type":"execute_result"}],"source":["import nltk\n","from nltk import word_tokenize, sent_tokenize\n","from nltk.tokenize import RegexpTokenizer\n","from nltk.util import ngrams\n","\n","nltk.download(\"punkt\")\n"]},{"cell_type":"markdown","id":"9a1b4cda","metadata":{"id":"9a1b4cda"},"source":["1\\. Выделите из текста n-граммы."]},{"cell_type":"code","execution_count":3,"id":"23e15cdb","metadata":{"executionInfo":{"elapsed":244,"status":"ok","timestamp":1704963606114,"user":{"displayName":"Никита Блохин","userId":"16402972581398673009"},"user_tz":-180},"id":"23e15cdb"},"outputs":[],"source":["text = \"\"\"Вода это жидкость которая имеет свойство быть водой.\n","Вода состоит из молекул, которые выглядят как вода\"\"\"\n"]},{"cell_type":"code","execution_count":4,"id":"0c02348e","metadata":{},"outputs":[{"data":{"text/plain":["[('вода',), ('это',), ('жидкость',), ('которая',), ('имеет',)]"]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["tokenizer = RegexpTokenizer(r\"\\w+\")\n","\n","sents = sent_tokenize(text)\n","unigrams = []\n","bigrams = []\n","\n","for s in sents:\n","    words = tokenizer.tokenize(s.lower())\n","    unigrams.extend(ngrams(words, 1))\n","    bigrams.extend(ngrams(words, 2))\n","unigrams[:5]\n"]},{"cell_type":"code","execution_count":5,"id":"zLdjyLB4xSt0","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7,"status":"ok","timestamp":1704963949632,"user":{"displayName":"Никита Блохин","userId":"16402972581398673009"},"user_tz":-180},"id":"zLdjyLB4xSt0","outputId":"68bcbb3c-bcce-456b-ab78-fcf3a8089cd5"},"outputs":[{"data":{"text/plain":["[('вода', 'это'),\n"," ('это', 'жидкость'),\n"," ('жидкость', 'которая'),\n"," ('которая', 'имеет'),\n"," ('имеет', 'свойство')]"]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["bigrams[:5]\n"]},{"cell_type":"markdown","id":"eff10835","metadata":{"id":"eff10835"},"source":["2. Рассчитайте вероятности  $P(вода)$, $P(это|вода)$, $P(состоит|вода)$.\n","\n","$$P(w_i) = \\frac{C(w_i)}{N}$$\n","$$P(w_i|w_{i-1})=\\frac{C(w_{i-1} w_i)}{C(w_{i-1})}$$"]},{"cell_type":"code","execution_count":21,"id":"mj8R7e0uxWY0","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1,"status":"ok","timestamp":1704964178245,"user":{"displayName":"Никита Блохин","userId":"16402972581398673009"},"user_tz":-180},"id":"mj8R7e0uxWY0","outputId":"f13e49b9-2ede-4c7e-bff6-b8efda01bf6a"},"outputs":[{"data":{"text/plain":["0.1875"]},"execution_count":21,"metadata":{},"output_type":"execute_result"}],"source":["unigram = (\"вода\",)\n","c = unigrams.count(unigram)\n","N = len(unigrams)\n","c / N\n"]},{"cell_type":"code","execution_count":24,"id":"mXcw7UYHyeXw","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7,"status":"ok","timestamp":1704964462159,"user":{"displayName":"Никита Блохин","userId":"16402972581398673009"},"user_tz":-180},"id":"mXcw7UYHyeXw","outputId":"2373c11d-a5c0-4520-a672-d56f90ec9a8e"},"outputs":[{"data":{"text/plain":["(1, 3, 0.3333333333333333)"]},"execution_count":24,"metadata":{},"output_type":"execute_result"}],"source":["bigram = (\"вода\", \"это\")\n","c_num = bigrams.count(bigram)\n","c_denom = unigrams.count(unigram)\n","c_num, c_denom, c_num / c_denom\n"]},{"cell_type":"code","execution_count":36,"id":"fd77e796","metadata":{},"outputs":[{"data":{"text/plain":["array([0.3645444 , 0.25543054, 0.22314313, 0.3645444 ])"]},"execution_count":36,"metadata":{},"output_type":"execute_result"}],"source":["from sklearn.feature_extraction.text import TfidfVectorizer\n","\n","corpus = [\n","    \"This is the first document.\",\n","    \"This document is the second document.\",\n","    \"And this is the third one.\",\n","    \"Is this the first document?\",\n","]\n","vectorizer = TfidfVectorizer(smooth_idf=False)\n","X = vectorizer.fit_transform(corpus)\n","vectorizer.get_feature_names_out()\n","\n","term = 'this'\n","term_id = vectorizer.vocabulary_[term]\n","X.toarray()[:, term_id]"]},{"cell_type":"code","execution_count":35,"id":"315bf72f","metadata":{},"outputs":[{"data":{"text/plain":["0.2"]},"execution_count":35,"metadata":{},"output_type":"execute_result"}],"source":["import numpy as np\n","\n","doc_id = 0\n","term = \"this\"\n","\n","doc_text = corpus[doc_id].lower()\n","\n","tf = doc_text.count(term) / len(doc_text.split())\n","df: int = len([doc for doc in corpus if term in doc.lower()])\n","idf = np.log(len(corpus) / df) + 1\n","tf * idf"]},{"cell_type":"code","execution_count":29,"id":"4a615986","metadata":{},"outputs":[{"data":{"text/plain":["4"]},"execution_count":29,"metadata":{},"output_type":"execute_result"}],"source":["len([doc for doc in corpus if term in doc.lower()])"]},{"cell_type":"code","execution_count":26,"id":"ylLRkzvXyeQY","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":229,"status":"ok","timestamp":1704964550942,"user":{"displayName":"Никита Блохин","userId":"16402972581398673009"},"user_tz":-180},"id":"ylLRkzvXyeQY","outputId":"d3cfb8c0-40b5-499d-ec0f-8f64bcdf3952"},"outputs":[{"data":{"text/plain":["0"]},"execution_count":26,"metadata":{},"output_type":"execute_result"}],"source":["bigrams.count((\"это\", \"состоит\"))"]},{"cell_type":"markdown","id":"686788c2","metadata":{"id":"686788c2"},"source":["3. Рассчитайте вероятности  $P_L(вода)$, $P_L(это|вода)$, $P_L(состоит|вода)$.\n","\n","$$P_L(w_i) = \\frac{C(w_i)+1}{N+V}$$ \n","\n","$$P_L(w_i|w_{i-1})=\\frac{C(w_{i-1} w_i)+1}{C(w_{i-1})+V}$$"]},{"cell_type":"code","execution_count":null,"id":"We8pDiXjz-7h","metadata":{"id":"We8pDiXjz-7h"},"outputs":[],"source":[]},{"cell_type":"markdown","id":"610d0f40","metadata":{"id":"610d0f40"},"source":["## Задачи для самостоятельного решения"]},{"cell_type":"markdown","id":"f02d1d0d","metadata":{"id":"f02d1d0d"},"source":["<p class=\"task\" id=\"1\"></p>\n","\n","1\\. Считайте файл `data/moya-semia/Лучше кошки зверя нет 2.csv`. Получите список предложений из сообщений. Приведите предложения к нижнему регистру и удалите все символы, кроме букв и пробелов. Получите список слов (униграмм) и биграмм."]},{"cell_type":"markdown","id":"2a170a1d","metadata":{"id":"2a170a1d"},"source":["<p class=\"task\" id=\"2\"></p>\n","\n","2\\. Получите распределение вероятностей для униграм $P(w_i) = \\frac{C(w_i)}{N}$, где $N$ - количество униграм, $C(w_i)$ - частота использования токена $w_i$. Получите распределение условных вероятностей для биграмм $P(w_i|w_{i-1})=\\frac{C(w_{i-1} w_i)}{C(w_{i-1})}$ ($C(w_{i-1} w_i)$ - частота использования словосочетания $w_{i-1}w_i$)."]},{"cell_type":"markdown","id":"c9d6c4f1","metadata":{"id":"c9d6c4f1"},"source":["<p class=\"task\" id=\"3\"></p>\n","\n","3\\.Воспользовавшись полученными вероятностями, сгенерируйте текст длиной не более 20 слов, начинающийся с токена \"мой\". При генерации текста выбирайте слово с наибольшей вероятностью соответствующего биграмма. Выведите полученный текст на экран."]},{"cell_type":"code","execution_count":null,"id":"4KhRR1Ow01xb","metadata":{"id":"4KhRR1Ow01xb"},"outputs":[],"source":[]},{"cell_type":"markdown","id":"EWHV2ZBx067f","metadata":{"id":"EWHV2ZBx067f"},"source":["P(любимый|мой), P(котик|мой), ...\n"]},{"cell_type":"markdown","id":"0EkkvaxZ1F3D","metadata":{"id":"0EkkvaxZ1F3D"},"source":["P(x|любимый)"]},{"cell_type":"markdown","id":"4039fcbf","metadata":{"id":"4039fcbf"},"source":["<p class=\"task\" id=\"4\"></p>\n","\n","4\\.Воспользовавшись полученными вероятностями, сгенерируйте текст длиной не более 20 символов, начинающийся с токена \"мой\". При генерации текста выбирайте слово пропорционально вероятностям соответствующих биграммов. Выведите полученный текст на экран."]},{"cell_type":"markdown","id":"J2bmwaTB1Wjl","metadata":{"id":"J2bmwaTB1Wjl"},"source":["P(любимый|мой), P(котик|мой), ...\n","0.7             0.3"]},{"cell_type":"code","execution_count":null,"id":"7OlAQo1m1V15","metadata":{"id":"7OlAQo1m1V15"},"outputs":[],"source":[]},{"cell_type":"markdown","id":"bde3ee55","metadata":{"id":"bde3ee55"},"source":["<p class=\"task\" id=\"5\"></p>\n","\n","5\\. Получите распределение вероятностей для униграм, воспользовавшись сглаживанием Лапласа: $P_L(w_i) = \\frac{C(w_i)+1}{N+V}$, где $V$ - количество уникальных униграмм. Получите распределение условных вероятностей для биграмм $P_L(w_i|w_{i-1})=\\frac{C(w_{i-1} w_i)+1}{C(w_{i-1})+V}$"]},{"cell_type":"markdown","id":"56ed1b9e","metadata":{"id":"56ed1b9e"},"source":["<p class=\"task\" id=\"6\"></p>\n","\n","6\\.Воспользовавшись полученными после сглаживания вероятностями, сгенерируйте текст длиной не более 20 символов, начинающийся с токена \"мой\". При генерации текста выбирайте слово пропорционально вероятностям соответствующих биграммов. Выведите полученный текст на экран."]},{"cell_type":"markdown","id":"8e93617c","metadata":{"id":"8e93617c"},"source":["<p class=\"task\" id=\"7\"></p>\n","\n","7\\. Рассчитайте перплексию для текста \"Котя пришел домой с хромой лапой\" для четырех моделей: на 1/2-граммах и с/без использования сглаживания Лапласа. Сведите результат в таблицу. Повторите вычисления для текста \"После пар я поеду кормить своего кота\", используя доступные модели.\n","\n","$Perplexity(W) = P(w_1w_2...w_N)^{-\\frac{1}{N}}$\n","\n","Для модели на униграммах $P(w_1w_2...w_N) = \\Pi_{i=1}^{N}{P(w_i)}$\n","\n","Для модели на биграммах $P(w_1w_2...w_N) = \\Pi_{i=2}^{N}{P(w_i|w_{i-1})}$"]},{"cell_type":"code","execution_count":null,"id":"3fd5addc","metadata":{"id":"3fd5addc"},"outputs":[],"source":["test1 = \"После пар я поеду кормить своего кота\".lower()\n","test2 = \"Котя пришел домой с хромой лапой\".lower()\n"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.9"}},"nbformat":4,"nbformat_minor":5}
